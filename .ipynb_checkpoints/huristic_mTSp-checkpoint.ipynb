{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1d2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np # used for scientific computing\\n\",\n",
    "import pandas as pd # used for data analysis and manipulation\\n\",\n",
    "import matplotlib.pyplot as plt # used for visualization and plotting\\n\",\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6b5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get these 2 as an input\n",
    "name_of_file = 'real_data_with_duration_time'\n",
    "number_of_resources = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632a89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data \n",
    "df = pd.read_excel(f'Data/{name_of_file}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_the_same_location(place_1, place_2):\n",
    "    return True if place_1['Latitude'] == place_2['Latitude'] and place_1['Longitude'] == place_2['Longitude'] else False\n",
    "\n",
    "\n",
    "def merge_duplicates(df):\n",
    "    duplicates_indexes = []\n",
    "    dict_of_duplicates = dict({})\n",
    "    res = df.copy()\n",
    "    for index_1, row_1 in df.iterrows():\n",
    "        if index_1 not in duplicates_indexes:\n",
    "            print(index_1)\n",
    "            print(duplicates_indexes)\n",
    "            current_duplicates = []\n",
    "            for index_2, row_2 in df.iterrows():\n",
    "                if index_1 < index_2 and index_2 not in duplicates_indexes and is_the_same_location(row_1, row_2):\n",
    "                        res.drop(index=index_2, axis=0, inplace=True)\n",
    "                        current_duplicates.append(index_2)\n",
    "            duplicates_indexes += current_duplicates\n",
    "            dict_of_duplicates[index_1] = current_duplicates\n",
    "    return res, dict_of_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dddea2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>Id</th>\n",
       "      <th>AppointmentNumber</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>DurationInMinutes</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>IDC_Index__c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJmbQAE</td>\n",
       "      <td>SA-3699</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476372</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.179075</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJmcQAE</td>\n",
       "      <td>SA-3700</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.478785</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.178168</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJlbQAE</td>\n",
       "      <td>SA-3637</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476777</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.177451</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJlcQAE</td>\n",
       "      <td>SA-3638</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476031</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.178510</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJldQAE</td>\n",
       "      <td>SA-3639</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476653</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.177475</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJUcQAM</td>\n",
       "      <td>SA-2584</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476960</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.176940</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJUdQAM</td>\n",
       "      <td>SA-2585</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476852</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.179477</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJUeQAM</td>\n",
       "      <td>SA-2586</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.477306</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.177747</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJUkQAM</td>\n",
       "      <td>SA-2592</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.477306</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.177747</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>[ServiceAppointment]</td>\n",
       "      <td>08p4L000000lJUlQAM</td>\n",
       "      <td>SA-2593</td>\n",
       "      <td>2021-10-08T22:59:00.000+0000</td>\n",
       "      <td>19.476777</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.177451</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _                  Id AppointmentNumber  \\\n",
       "0     [ServiceAppointment]  08p4L000000lJmbQAE           SA-3699   \n",
       "1     [ServiceAppointment]  08p4L000000lJmcQAE           SA-3700   \n",
       "2     [ServiceAppointment]  08p4L000000lJlbQAE           SA-3637   \n",
       "3     [ServiceAppointment]  08p4L000000lJlcQAE           SA-3638   \n",
       "4     [ServiceAppointment]  08p4L000000lJldQAE           SA-3639   \n",
       "...                    ...                 ...               ...   \n",
       "1495  [ServiceAppointment]  08p4L000000lJUcQAM           SA-2584   \n",
       "1496  [ServiceAppointment]  08p4L000000lJUdQAM           SA-2585   \n",
       "1497  [ServiceAppointment]  08p4L000000lJUeQAM           SA-2586   \n",
       "1498  [ServiceAppointment]  08p4L000000lJUkQAM           SA-2592   \n",
       "1499  [ServiceAppointment]  08p4L000000lJUlQAM           SA-2593   \n",
       "\n",
       "                           DueDate   Latitude  DurationInMinutes  Longitude  \\\n",
       "0     2021-10-08T22:59:00.000+0000  19.476372                  8 -99.179075   \n",
       "1     2021-10-08T22:59:00.000+0000  19.478785                  8 -99.178168   \n",
       "2     2021-10-08T22:59:00.000+0000  19.476777                  8 -99.177451   \n",
       "3     2021-10-08T22:59:00.000+0000  19.476031                  8 -99.178510   \n",
       "4     2021-10-08T22:59:00.000+0000  19.476653                  8 -99.177475   \n",
       "...                            ...        ...                ...        ...   \n",
       "1495  2021-10-08T22:59:00.000+0000  19.476960                  8 -99.176940   \n",
       "1496  2021-10-08T22:59:00.000+0000  19.476852                  8 -99.179477   \n",
       "1497  2021-10-08T22:59:00.000+0000  19.477306                  8 -99.177747   \n",
       "1498  2021-10-08T22:59:00.000+0000  19.477306                  8 -99.177747   \n",
       "1499  2021-10-08T22:59:00.000+0000  19.476777                  8 -99.177451   \n",
       "\n",
       "      IDC_Index__c  \n",
       "0             1257  \n",
       "1              863  \n",
       "2              740  \n",
       "3             1159  \n",
       "4              739  \n",
       "...            ...  \n",
       "1495           823  \n",
       "1496           324  \n",
       "1497             5  \n",
       "1498            30  \n",
       "1499           813  \n",
       "\n",
       "[1500 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique, dict_of_duplicates = merge_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9d2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    \"\"\"\n",
    "    Vertex on the graph G is a job with:\n",
    "    id: index in the given excel (in order to update it well),\n",
    "    location - latitude, longitude,\n",
    "    expect duration time in minutes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id, lat, lon, duration_time):\n",
    "        self.id = id\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.index = -1\n",
    "        self.weight = duration_time\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'({self.lat}, {self.lon}, {self.weight})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd24f4",
   "metadata": {},
   "source": [
    "# Note \n",
    "\n",
    "* we do not calculate the driving distance. \n",
    "* we assume that the speed in any location is the same. Which is probably wrong.\n",
    "\n",
    "Results may improve by changing the functions compute_distance, proxy_time_between_u_v to functions that estimate time according to the driving way\n",
    "\n",
    "\n",
    "##### It is enough to change these calculation only in the Edge class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5fb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge:\n",
    "    \"\"\"\n",
    "    Edge is connect between two vetices.(Jobs)\n",
    "    The weight include also the duration time.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, u, v):\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        # Each vertex is incident to exactly two edges of the cycle, so we can define the weight of an edge as:\n",
    "        self.weight =  0.5 * (u.weight + v. weight) + self.proxy_time_between_u_v()\n",
    "        \n",
    "    \n",
    "    def proxy_time_between_u_v(self, kmh=7):\n",
    "        \"\"\"\n",
    "        return the time (under assumption) to go from u to v\n",
    "        \"\"\"\n",
    "        d = self.compute_distance()\n",
    "        \n",
    "        return d # / kmh \n",
    "    \n",
    "    \n",
    "    def compute_distance(self):\n",
    "        \"\"\"\n",
    "        compute the distance (km) between two lat-long coordinates\n",
    "\n",
    "        \"\"\"    \n",
    "        # radius of the Earth\n",
    "        R = 6373.0\n",
    "\n",
    "        distance_lat = self.u.lat - self.v.lat\n",
    "        distance_long = self.u.lon - self.v.lon\n",
    "\n",
    "        #Haverinse formula \n",
    "        x = math.sin(distance_lat / 2)**2 + math.cos(self.v.lat) * math.cos(self.u.lat) * math.sin(distance_long / 2)**2\n",
    "\n",
    "        y = 2 * math.atan2(math.sqrt(x), math.sqrt(1 - x))\n",
    "\n",
    "        return (R * y) # / 1000\n",
    "    \n",
    "    \n",
    "    def consist_vertex(self, v):\n",
    "        return True if (self.u == v or self.v == v) else False\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'[{self.u}, {self.v}] , w(e) = {self.weight}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14741949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_i:\n",
    "    \"\"\"\n",
    "    Create a subgraph G_i\n",
    "    \"\"\"\n",
    "    def __init__(self, all_vertices, V_i, E_i):\n",
    "        self.V = V_i \n",
    "        self.length = len(V_i)\n",
    "        self.E = E_i\n",
    "        self.weight = sum(edge.weight for edge in E_i) \n",
    "        margin_weight_dict = {v.id: (v, self.init_margin_weight(v)) for v in all_vertices}\n",
    "        # sorted dictionary\n",
    "        self.margin_weight_dict = dict(sorted(margin_weight_dict.items(), key=lambda item: item[1][1], reverse=True))\n",
    "        self.size = (2 / (self.length - 1))  * (self.weight)  \n",
    "    \n",
    "    \n",
    "    def init_margin_weight(self, v):\n",
    "        \"\"\"\n",
    "        margin_weight(v) = sum of w(v', v) for v' in V_i\n",
    "        \"\"\"\n",
    "        relevant_edges = [Edge(u, v) for u in self.V]\n",
    "        return sum(edge.weight for edge in relevant_edges)\n",
    "    \n",
    "    \n",
    "    def get_size_after_transfer_remove(self, v):\n",
    "        \"\"\"\n",
    "        return the size if the remove operation will be executed\n",
    "        \"\"\"\n",
    "        return (2 / (self.length - 2)) * (self.weight - self.margin_weight_dict.get(v.id)[1]) \n",
    "        \n",
    "    \n",
    "    def get_size_after_transfer_add(self, v):\n",
    "        \"\"\"\n",
    "        return the size if the add operation will be executed\n",
    "        \"\"\"\n",
    "        return (2 / self.length) * (self.weight + self.margin_weight_dict.get(v.id)[1])\n",
    "    \n",
    "    \n",
    "    def get_size_after_swap(self, v, u):\n",
    "        \"\"\"\n",
    "        return the size if the swap operation will be executed such that v in V_i and u is from another sub-graph\n",
    "        \"\"\"\n",
    "        return self.weight - self.margin_weight_dict.get(v.id)[1] + self.margin_weight_dict.get(u.id)[1] - Edge(u, v).weight\n",
    "    \n",
    "    \n",
    "    def add_vertex(self, v):\n",
    "        \"\"\"\n",
    "        Add vertex to the graph_i.\n",
    "        Update the the fields as needed.\n",
    "        \"\"\"\n",
    "        self.V += [v]\n",
    "        self.length += 1\n",
    "        self.weight += self.margin_weight_dict.get(v.id)[1]\n",
    "        for key, value in self.margin_weight_dict.items():\n",
    "            self.margin_weight_dict[key] = (value[0], value[1] + Edge(v, value[0]).weight)\n",
    "        self.size = (2 / (self.length - 1))  * (self.weight) \n",
    "        \n",
    "    def remove_vertex(self, v):\n",
    "        \"\"\"\n",
    "        Remove vertex from graph_i.\n",
    "        Update the the fields as needed.\n",
    "        \"\"\"\n",
    "        for idx, u in enumerate(self.V):\n",
    "            if u == v:\n",
    "                _ = self.V.pop(idx)\n",
    "        self.weight -= self.margin_weight_dict.get(v.id)[1]\n",
    "        for key, value in self.margin_weight_dict.items():\n",
    "            self.margin_weight_dict[key] = (value[0], value[1] - Edge(v, value[0]).weight)\n",
    "        self.length -= 1\n",
    "        self.size = (2 / (self.length - 1))  * (self.weight) \n",
    "        \n",
    "    def swap(self, v, u):\n",
    "        \"\"\"\n",
    "        Swap vertices between graph_i and graph_j such that i != j.\n",
    "        Remove v from graph_i and add u to graph_i.\n",
    "        \n",
    "        Note: in order to execute the swap coorrectly - we need to execute it on both graphs (aka - Gi, Gj)\n",
    "        \n",
    "        Input:\n",
    "        - v: v in graph_i \n",
    "        - u: u in graph_j such that u in all_vertices\n",
    "        \"\"\"\n",
    "        self.add_vertex(u)\n",
    "        self.remove_vertex(v)\n",
    "#         for idx, v1 in enumerate(self.V):\n",
    "#             if v1 == v:\n",
    "#                 _ = self.V.pop(idx)\n",
    "#         self.V += [u]\n",
    "#         self.weight = self.weight - self.margin_weight_dict.get(v.id)[1] + self.margin_weight_dict.get(u.id)[1] - Edge(v, u).weight\n",
    "#         for key, value in self.margin_weight_dict.items():\n",
    "#             self.margin_weight_dict[key] = (value[0], value[1] - Edge(v, value[0]).weight + Edge(u, value[0]).weight)\n",
    "#         self.size = (2 / (self.length - 1))  * (self.weight)\n",
    "\n",
    "    def get_jobs_location(self):\n",
    "        \"\"\"\n",
    "        return latitude list and longitude list of the vertices in graph_i\n",
    "        \"\"\"\n",
    "        lat_lst = [v.lat for v in self.V]\n",
    "        lon_lst = [v.lon for v in self.V]\n",
    "        return lat_lst, lon_lst\n",
    "    \n",
    "    def plot_sub_graph(self):\n",
    "        lat, lon = self.get_jobs_location()\n",
    "        plt.scatter(lat, lon)\n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a0ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_partition(G, number_of_resources):\n",
    "    \"\"\"\n",
    "    Initiate a Partiton P=[G1, G2, ..., Gm] where m = number of resources(workers)\n",
    "    \"\"\"\n",
    "    V = G[0]\n",
    "    Gs = []\n",
    "\n",
    "    number_of_jobs = len(V)\n",
    "    Gi_size = number_of_jobs // number_of_resources\n",
    "    remider = number_of_jobs % number_of_resources\n",
    "    v_index = 0 \n",
    "    for i in range(number_of_resources):\n",
    "        length = Gi_size + 1 if remider > i else Gi_size\n",
    "        V_i = [V[j] for j in range(v_index, length + v_index)]\n",
    "        v_index += length\n",
    "        E_i = [Edge(V_i[j1], V_i[j2]) for j1 in range(length) for j2 in range(j1 + 1, length)]\n",
    "        Gs.append(Graph_i(V, V_i, E_i)) \n",
    "    \n",
    "    plot_partition(Gs, 'init Partition')\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6e49e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "\n",
    "def find_best_transfer(G1, G2):\n",
    "    \"\"\"\n",
    "    find the best vertices to execute transfer from G1 to G2 \n",
    "    return None if there is not exists such a transfer \n",
    "    \"\"\"\n",
    "    max_size = max(G1.size, G2.size)\n",
    "    best_v1 = None\n",
    "    \n",
    "    for v1 in G1.V:\n",
    "        \n",
    "        current_size = max(G1.get_size_after_transfer_remove(v1), G2.get_size_after_transfer_add(v1))\n",
    "        if current_size < max_size:\n",
    "            max_size = current_size\n",
    "            best_v1 = v1\n",
    "    \n",
    "    return None if best_v1 is None else best_v1\n",
    "\n",
    "\n",
    "def find_best_swap(G1, G2):\n",
    "    \"\"\"\n",
    "    find the best vertices to execute swap between G1 and G2 \n",
    "    return None if there is not exists such a swap \n",
    "    \"\"\"\n",
    "    max_size = max(G1.size, G2.size)\n",
    "    best_v1 = None\n",
    "    best_v2 = None\n",
    "    \n",
    "    for v1 in G1.V:\n",
    "        for v2 in G2.V:\n",
    "            current_size = max(G1.get_size_after_swap(v1, v2), G2.get_size_after_swap(v2, v1))\n",
    "            if (current_size < max_size):\n",
    "                max_size = current_size\n",
    "                best_v1 = v1\n",
    "                best_v2 = v2\n",
    "    \n",
    "    return None if best_v1 is None else best_v1, best_v2\n",
    "\n",
    "    \n",
    "def improve_partition(Gs):\n",
    "    \"\"\"\n",
    "    Algorithm 1 - improve partition by transfer and swaps vertices \n",
    "    \"\"\"\n",
    "    # num_of_resources == len(Gs) => True\n",
    "    num_of_resources = len(Gs)\n",
    "    unchecked_sub_graphs_pairs = [(i, j) for i in range(num_of_resources) for j in range(num_of_resources) if i != j]\n",
    "    unchecked_transfers = [(i, j) for i in range(num_of_resources) for j in range(num_of_resources) if Gs[i].size > Gs[j].size]\n",
    "    \n",
    "    while len(unchecked_sub_graphs_pairs) > 0:\n",
    "        current_transfer = unchecked_sub_graphs_pairs[0]\n",
    "        G1 = Gs[current_transfer[0]]\n",
    "        G2 = Gs[current_transfer[1]]\n",
    "        \n",
    "        if current_transfer in unchecked_transfers:\n",
    "            v1 = find_best_transfer(G1, G2)\n",
    "            if v1:\n",
    "                G1.remove_vertex(v1)\n",
    "                G2.add_vertex(v1)                \n",
    "            else:                \n",
    "                unchecked_transfers.remove(current_transfer)\n",
    "        else:  \n",
    "            v1, v2 = find_best_swap(G1, G2)\n",
    "            if v1:\n",
    "                G1.swap(v1, v2)\n",
    "                G2.swap(v2, v1)                \n",
    "            else:\n",
    "                unchecked_sub_graphs_pairs.pop(0)\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e0df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2\n",
    "\n",
    "def find_minizer_of_margin(Gs, v):\n",
    "    \"\"\"\n",
    "    Find the index of the sub-graph_i in Gs such that margin_weight(Gi, v) is minimal. \n",
    "    \"\"\"\n",
    "    min_idx = 0\n",
    "    for idx, G in enumerate(Gs):\n",
    "        if G.margin_weight_dict.get(v.id)[1] < Gs[min_idx].margin_weight_dict.get(v.id)[1]:\n",
    "            min_idx = idx\n",
    "    return idx\n",
    "\n",
    "def transfer_outliers(Gs, alpha=1.5):\n",
    "    \"\"\"\n",
    "    Algorithm 2 - transfer ouliers to their compatible graph\n",
    "    Input:\n",
    "    Gs - partition of graph G\n",
    "    alpha - control the number of detected outliers which decrease as long as alpha increase, need to be bigger than 1.  \n",
    "    \"\"\"\n",
    "    outliers = []\n",
    "    for idx, G in enumerate(Gs):\n",
    "        for v in G.V:\n",
    "            if G.margin_weight_dict.get(v.id)[1] > (alpha * 2 * G.weight) / G.length :\n",
    "                new_G_idx = find_minizer_of_margin(Gs, v)\n",
    "                if new_G_idx != idx:\n",
    "                    outliers.append((v, idx, new_G_idx))\n",
    "    \n",
    "    for t in outliers:\n",
    "        Gs[idx].remove_vertex(v)\n",
    "        Gs[new_G_idx].add_vertex(v)\n",
    "        \n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a3e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 3 \n",
    "def average_hamilton_partition(G, number_of_resources):\n",
    "    \"\"\"\n",
    "    Algorithm 3 - Partition a graph G by two alternating phasesâ€” \n",
    "        improvement (Algorithm 1) and transferring outliers (Algorithm 2)\n",
    "    \"\"\"\n",
    "    Gs = get_random_partition(G, number_of_resources)\n",
    "    _ = improve_partition(Gs)\n",
    "    Ca = max([G.size for G in Gs])\n",
    "    new_Ca = Ca\n",
    "    while Ca == new_Ca:\n",
    "        print(f'Ca = {Ca}')\n",
    "        new_Gs = Gs.copy()\n",
    "        _ = transfer_outliers(new_Gs, 1.005)\n",
    "        _ = improve_partition(new_Gs)\n",
    "        new_Ca = max([G.size for G in new_Gs])\n",
    "        print(f'new_Ca =  {new_Ca}')\n",
    "        if Ca > new_Ca:\n",
    "            Gs = new_Gs\n",
    "            Ca = new_Ca\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9e55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-opt Algorithm adapted from https://en.wikipedia.org/wiki/2-opt\n",
    "\n",
    "# Calculate the euclidian distance in n-space of the route r traversing jobs j, ending at the path start.\n",
    "path_distance = lambda r,j: np.sum([np.linalg.norm(j[r[p]] - j[r[p - 1]]) for p in range(len(r))])\n",
    "\n",
    "# Reverse the order of all elements from element i to element k in array r.\n",
    "two_opt_swap = lambda r,i,k: np.concatenate((r[0:i], r[k:- len(r) + i - 1:-1],r[k + 1:len(r)]))\n",
    "\n",
    "def two_opt(jobs,improvement_threshold): \n",
    "    route = np.arange(jobs.shape[0])\n",
    "    # Initialize the improvement factor.\n",
    "    improvement_factor = 1 \n",
    "    best_distance = path_distance(route,jobs)\n",
    "    \n",
    "    while improvement_factor > improvement_threshold: \n",
    "        # Record the distance at the beginning of the loop.\n",
    "        distance_to_beat = best_distance\n",
    "        \n",
    "        for swap_first in range(1,len(route)-2):\n",
    "            for swap_last in range(swap_first+1,len(route)): \n",
    "                # try reversing the order of these jobs\n",
    "                new_route = two_opt_swap(route,swap_first,swap_last) \n",
    "                # check the total distance with this modification.\n",
    "                new_distance = path_distance(new_route,jobs)\n",
    "                \n",
    "                if new_distance < best_distance: \n",
    "                    route = new_route\n",
    "                    best_distance = new_distance \n",
    "        # Calculate how much the route has improved.\n",
    "        improvement_factor = 1 - best_distance/distance_to_beat \n",
    "    return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47974282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-TSP\n",
    "def one_TSP(Gi, offset=0):\n",
    "    \"\"\"\n",
    "    Execute 1-TSP optimal algorithm on the give sub-graph_i\n",
    "    \n",
    "    Input:\n",
    "    Gi - sub-graph i\n",
    "    offset - the index to start from.\n",
    "    \"\"\"\n",
    "    R = 6371\n",
    "    lat_lst, lon_lst = Gi.get_jobs_location()\n",
    "    \n",
    "    lat_lst_radians = np.array([math.radians(lat) for lat in lat_lst])\n",
    "    lon_lst_radians = np.array([math.radians(lon) for lon in lon_lst])\n",
    "    lon_cos = np.array([math.cos(lon_r) for lon_r in lon_lst_radians])\n",
    "    x =  lon_cos * np.array([math.cos(lat_r) for lat_r in lat_lst_radians]) * R\n",
    "    y= lon_cos * np.array([math.sin(lat_r) for lat_r in lat_lst_radians]) * R\n",
    "    jobs_locations = pd.DataFrame({\"X\": x, \"Y\": y})\n",
    "    df = jobs_locations.copy()\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 100), copy=True)\n",
    "    scaled_df = scaler.fit_transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=['x1', 'x2'])\n",
    "    \n",
    "    jobs_location = np.asarray(jobs_locations)\n",
    "    scaled = np.asarray(scaled_df)\n",
    "    \n",
    "    route = two_opt(scaled, 0.001)\n",
    "    \n",
    "    # update vertices index\n",
    "    for v, idx in zip(Gi.V, route):\n",
    "        v.index = idx + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8af7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 4 \n",
    "def m_TSP(G, number_of_resources):\n",
    "    \"\"\"\n",
    "    Algorithm 4 - achieve a good patition by AHP, \n",
    "        then execute 1-TSP on each sub-graph_i in the pratition.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    Gs = average_hamilton_partition(G, number_of_resources)\n",
    "    print('AHP - DONE!')\n",
    "    for Gi in Gs:\n",
    "        one_TSP(Gi, offset)\n",
    "        offset += Gi.length\n",
    "    return Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e319761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_partition(Gs, title):\n",
    "    \"\"\"\n",
    "    Ploting the partition Gs\n",
    "    \"\"\"\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(Gs) * 5))\n",
    "    colors = colors[::5]\n",
    "    for G, c in zip(Gs, colors):\n",
    "        lat_lst, lon_lst = G.get_jobs_location()\n",
    "        plt.scatter(lat_lst, lon_lst, color=c)\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2f0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the relevant columns\n",
    "lat_lst = df['Latitude']\n",
    "lon_lst = df['Longitude']\n",
    "duration_lst = df['DurationInMinutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b082e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the graph G\n",
    "number_of_jobs = df.shape[0]\n",
    "V = [Vertex(i, lat_lst[i], lon_lst[i], duration_lst[i]) for i in range(number_of_jobs)]\n",
    "E = [Edge(V[i1], V[i2]) for i1 in range(number_of_jobs) for i2 in range(i1 + 1, number_of_jobs)]\n",
    "G = (V, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ca = 3342.63956376227\n",
      "new_Ca =  2914.361754859748\n",
      "Ca = 2914.361754859748\n",
      "new_Ca =  2816.7897521384652\n",
      "Ca = 2816.7897521384652\n",
      "new_Ca =  2697.9611810573238\n",
      "Ca = 2697.9611810573238\n",
      "new_Ca =  2586.010340836682\n",
      "Ca = 2586.010340836682\n",
      "new_Ca =  2425.7603290844686\n",
      "Ca = 2425.7603290844686\n",
      "new_Ca =  2399.9025850604635\n",
      "Ca = 2399.9025850604635\n",
      "new_Ca =  2360.504663924587\n",
      "Ca = 2360.504663924587\n",
      "new_Ca =  2353.096232077181\n",
      "Ca = 2353.096232077181\n",
      "new_Ca =  2338.160523864175\n",
      "Ca = 2338.160523864175\n",
      "new_Ca =  2310.304108668622\n",
      "Ca = 2310.304108668622\n",
      "new_Ca =  2298.2207123589033\n",
      "Ca = 2298.2207123589033\n",
      "new_Ca =  2294.3002703749885\n",
      "Ca = 2294.3002703749885\n",
      "new_Ca =  2290.1730470315183\n",
      "Ca = 2290.1730470315183\n",
      "new_Ca =  2281.8696010285516\n",
      "Ca = 2281.8696010285516\n",
      "new_Ca =  2273.5687952541084\n",
      "Ca = 2273.5687952541084\n",
      "new_Ca =  2263.1183975202466\n",
      "Ca = 2263.1183975202466\n",
      "new_Ca =  2255.007859987035\n",
      "Ca = 2255.007859987035\n",
      "new_Ca =  2251.4816953020136\n",
      "Ca = 2251.4816953020136\n",
      "new_Ca =  2249.1665846776905\n",
      "Ca = 2249.1665846776905\n",
      "new_Ca =  2240.4507823339923\n",
      "Ca = 2240.4507823339923\n",
      "new_Ca =  2236.4505887148234\n",
      "Ca = 2236.4505887148234\n",
      "new_Ca =  2233.8614528098165\n",
      "Ca = 2233.8614528098165\n",
      "new_Ca =  2223.670667562582\n",
      "Ca = 2223.670667562582\n",
      "new_Ca =  2220.5316350739195\n",
      "Ca = 2220.5316350739195\n",
      "new_Ca =  2217.4173694665255\n",
      "Ca = 2217.4173694665255\n",
      "new_Ca =  2214.047819941729\n",
      "Ca = 2214.047819941729\n",
      "new_Ca =  2208.04569550267\n",
      "Ca = 2208.04569550267\n",
      "new_Ca =  2204.5862515083004\n",
      "Ca = 2204.5862515083004\n",
      "new_Ca =  2195.0778719244713\n",
      "Ca = 2195.0778719244713\n"
     ]
    }
   ],
   "source": [
    "Gs = average_hamilton_partition(G, number_of_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "for Gi in Gs:\n",
    "    one_TSP(Gi, offset)\n",
    "    offset += Gi.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partition(Gs, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63670d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, G in enumerate(Gs):\n",
    "    print()\n",
    "    print(f'--------------- {idx} ---------------')\n",
    "    print(f'Size = {G.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8228593",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "lat, lon = Gs[i].get_jobs_location()\n",
    "plt.plot(lat, lon)\n",
    "print(len(Gs[i].V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c569b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sorted([(v.id, v.index) for G in Gs for v in G.V], key=lambda t:t[0])\n",
    "idx_column_results = np.array(res)[:,1]\n",
    "df['IDC_Index__c'] = idx_column_results\n",
    "#df.to_excel(f'results_(m_TSP)_considering_job_time.xlsx', sheet_name='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = m_TSP(G, number_of_resources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
